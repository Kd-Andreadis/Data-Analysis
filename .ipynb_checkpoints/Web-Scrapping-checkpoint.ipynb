{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1387be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY FOR ONE TIME RUN\n",
    "# 2 ways of installing: Through anaconda navigator->environments etc & through terminal of a specific environment *it also opens at\n",
    "# anaconda navigator->environments->'play button'\n",
    "\n",
    "# for mysql.connector I add 'mysql-connector-python'\n",
    "# for matplotlib I can use the alternative way of intalling: I write 'pip install matplotlib' in conda prompt\n",
    "# for textblob I write in prompt 'pip install textblob'\n",
    "# for pandas I write in prompt 'pip install pandas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c965d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  # ??\n",
    "import re\n",
    "import tweepy\n",
    "import mysql.connector\n",
    "from mysql.connector import Error   #Gia na fortwsw ta eidika errors gia sql connection\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import string  # ??\n",
    "import nltk  # ??\n",
    "from nltk.stem import WordNetLemmatizer  # ??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4af4b59",
   "metadata": {},
   "source": [
    "# WEB SCRAPPING (beautiful Soup)\n",
    "Tutorials:\n",
    "- With Pycharm:  https://oxylabs.io/blog/beautiful-soup-parsing-tutorial\n",
    "- With Jupiter Notebook:  https://www.youtube.com/watch?v=hWUqPUJWp3k&ab_channel=TEW22\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Needed steps:\n",
    "- Create a class inheriting from StreamListener\n",
    "- Using that class create a Stream object\n",
    "- Connect to the Twitter API using the Stream.\n",
    "\n",
    "Notes: <br>\n",
    "- The Key Differences Between Streaming APIs and REST APIs: https://www.nstream.io/the-key-differences-between-streaming-apis-and-rest-apis/ <br>\n",
    "UNFORTUNATELY, Streaming tweets are not permitted in free and basic versions of Twitter Developer\n",
    "https://stackoverflow.com/questions/76445414/twitter-streams-api-returns-403\n",
    "\n",
    "- Tweepy docmentation:\n",
    "https://docs.tweepy.org/en/stable/index.html\n",
    "\n",
    "We will use Twitter API v2, which uses 'Client' method (or interface) that returns a Twitter API object<br>\n",
    "https://docs.tweepy.org/en/stable/client.html#tweepy.Client\n",
    "https://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9\n",
    "\n",
    "Twitter Developer Portal\n",
    "https://developer.twitter.com/en/portal/dashboard\n",
    "\n",
    "Twitter queries\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5a273",
   "metadata": {},
   "source": [
    "# CONNECT TO DATABASE TO STORE RAW DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c292b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'case_st_twit'\n",
    "\n",
    "# CONNECT TO DATABASE AND CREATE THE TABLE THAT WE WILL STORE THE TWEETS\n",
    "try:\n",
    "    db = mysql.connector.connect(host='localhost', database = db_name , user='root', password='')\n",
    "    if db.is_connected():\n",
    "        print('Connected to MySQL Database')\n",
    "        cur = db.cursor()  # create object cursor from cursor method\n",
    "\n",
    "        # Creating the table of database\n",
    "        q = \"CREATE table r_tweets( \\\n",
    "                username VARCHAR(30) PRIMARY KEY, \\\n",
    "                tweet VARCHAR(280), \\\n",
    "                t_date VARCHAR(30), \\\n",
    "                n_ret INT(3), \\\n",
    "                loc VARCHAR(20), \\\n",
    "                n_fol INT(9), \\\n",
    "                n_twe INT(3), \\\n",
    "                hashtags VARCHAR(50), \\\n",
    "                commit;\"\n",
    "        cur.execute(q)\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    cur.execute(\"commit;\")\n",
    "    db.close()\n",
    "    print('Database connection closed!')\n",
    "\n",
    "# CONNECT TO DATABASE TO STORE THE FETCHED TWEETS AS RAW DATA\n",
    "try:\n",
    "    db = mysql.connector.connect(host='localhost', database= db_name, user='root', password='')\n",
    "    if db.is_connected():\n",
    "        cur = db.cursor()\n",
    "\n",
    "        for row in range(len(list1)):\n",
    "            # Before running the sql commands, we clean the text data from apostrophes <'>, in order to avoid losing data due to faulty comments in sql commands\n",
    "            q = \"INSERT INTO tweets (username, tweet, t_date, n_ret, loc, n_fol, n_twe, hashtags) VALUES ('\" \\\n",
    "            + re.sub(r'[\\']', ' ',str(list2[row])) + \"', '\" + re.sub(r'[\\']', ' ',str(list1[row])) + \"', '\" + str(list3[row]) + \\\n",
    "            \"', '\" + str(list4[row]) + \"', '\" + re.sub(r'[\\']', ' ',str(list5[row])) + \"', '\" + str(list6[row]) + \\\n",
    "            \"', '\" + str(list7[row]) + \"', '\"  + re.sub(r'[\\']', ' ',str(list8[row])) + \\\n",
    "            \"');\"\n",
    "\n",
    "            try:\n",
    "                print(q)\n",
    "                cur.execute(q)\n",
    "            except Error as e:\n",
    "                print(e)\n",
    "\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    cur.execute(\"commit;\")\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fb35b",
   "metadata": {},
   "source": [
    "# CLEANING OF DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33933c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw data from database\n",
    "try:\n",
    "    db = mysql.connector.connect(host='localhost', database = db_name, user='root', password='')\n",
    "\n",
    "    # Initialization for storing the tweets in pandas object 'data'\n",
    "    data = []\n",
    "    columns = ['user', 'tweet', 'date', 'n_ret', 'loc', 'n_fol', 'n_twe', 'hashtags']\n",
    "    if db.is_connected():\n",
    "        cur = db.cursor()  # create object cursor from cursor method\n",
    "\n",
    "        q = \"SELECT * FROM tweets;\"\n",
    "        cur.execute(q)\n",
    "        #Create the dataframe with all the data from database\n",
    "        data = pd.DataFrame(cur.fetchall(), columns=columns)\n",
    "\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    cur.execute(\"commit;\")\n",
    "    db.close()\n",
    "\n",
    "\n",
    "# Remove duplicate users. We want one tweet from every user\n",
    "data.drop_duplicates(subset =\"user\", keep = False, inplace = True)\n",
    "\n",
    "positive = 0\n",
    "negative = 0\n",
    "neutral = 0\n",
    "polarity = 0\n",
    "list9=[]\n",
    "for row in data.index:\n",
    "    # Remove punctuations\n",
    "    cleaned_tweet = ''.join(re.sub (\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])| (\\w+:\\ / \\ / \\S+)\", \" \", data['tweet'][row]))\n",
    "    # Remove the words with the @ symbol\n",
    "    cleaned_tweet = re.sub ('@\\S+', '', cleaned_tweet)\n",
    "    # Remove the Url's\n",
    "    cleaned_tweet = re.sub('((www.[^s]+)|(https?://[^s]+))', ' ', cleaned_tweet)\n",
    "    # Remove the hashtags\n",
    "    cleaned_tweet = re.sub ('#\\S+', '', cleaned_tweet)\n",
    "    # Remove the change row\n",
    "    cleaned_tweet = re.sub ('\\\\n', '', cleaned_tweet)\n",
    "    # Remove Stopwords\n",
    "    stopwords = set([\"\", \"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"A\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appreciate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"arise\", \"around\", \"as\", \"aside\", \"ask\", \"asking\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"B\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"been\", \"before\", \"beforehand\", \"beginnings\", \"behind\", \"below\", \"beside\", \"besides\", \"best\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"C\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"could\", \"couldn\", \"couldnt\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"ct\", \"cu\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"D\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doing\", \"don\", \"done\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"E\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"F\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"G\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"H\", \"h2\", \"h3\", \"had\", \"hadn\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"have\", \"haven\", \"having\", \"he\", \"hed\", \"hello\", \"help\", \"hence\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hes\", \"hh\", \"hi\", \"hid\", \"hither\", \"hj\", \"ho\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"im\", \"immediately\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"it\", \"itd\", \"its\", \"iv\", \"ix\", \"iy\", \"iz\", \"j\", \"J\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"K\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"ko\", \"l\", \"L\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"M\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"my\", \"n\", \"N\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"neither\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"O\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"otherwise\", \"ou\", \"ought\", \"our\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"P\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"Q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"R\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"S\", \"s2\", \"sa\", \"said\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"sent\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shed\", \"shes\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somehow\", \"somethan\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"sz\", \"t\", \"T\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"thats\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"these\", \"they\", \"theyd\", \"theyre\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"U\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"using\", \"usually\", \"ut\", \"v\", \"V\", \"va\", \"various\", \"vd\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"W\", \"wa\", \"was\", \"wasn\", \"wasnt\", \"way\", \"we\", \"wed\", \"welcome\", \"well\", \"well-b\", \"went\", \"were\", \"weren\", \"werent\", \"what\", \"whatever\", \"whats\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"whom\", \"whomever\", \"whos\", \"whose\", \"why\", \"wi\", \"widely\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"would\", \"wouldn\", \"wouldnt\", \"www\", \"x\", \"X\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"Y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"your\", \"youre\", \"yours\", \"yr\", \"ys\", \"yt\", \"z\", \"Z\", \"zero\", \"zi\", \"zz\"])\n",
    "    cleaned_tweet = ' '.join([word for word in str(cleaned_tweet).split() if word not in stopwords])\n",
    "\n",
    "    # Calculate the polarity of the sentiment analysis using textblob and store the results in the sentiment column of the dataframe\n",
    "    analysis = TextBlob(cleaned_tweet)\n",
    "    list9.append(analysis.sentiment.polarity)\n",
    "\n",
    "    if (analysis.sentiment.polarity == 0):\n",
    "        neutral += 1\n",
    "    elif (analysis.sentiment.polarity < 0):\n",
    "        negative += 1\n",
    "    elif (analysis.sentiment.polarity > 0):\n",
    "        positive += 1\n",
    "\n",
    "data.insert(loc=8, column='polarity', value = list9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224cbfe",
   "metadata": {},
   "source": [
    "# STORE THE CLEANED DATA IN DATABASE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a856888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A NEW TABLE IN DATABASE cl_tweets\n",
    "try:\n",
    "    db = mysql.connector.connect(host='localhost', database='twit_sent_an', user='root', password='')\n",
    "    if db.is_connected():\n",
    "        cur = db.cursor()  # create object cursor from cursor method\n",
    "\n",
    "        q = \"CREATE table cl_tweets( \\\n",
    "                username VARCHAR(30) PRIMARY KEY, \\\n",
    "                tweet VARCHAR(280), \\\n",
    "                t_date VARCHAR(30), \\\n",
    "                n_ret INT(3), \\\n",
    "                loc VARCHAR(20), \\\n",
    "                n_fol INT(9), \\\n",
    "                n_twe INT(3), \\\n",
    "                hashtags VARCHAR(50), \\\n",
    "                sentiment FLOAT(4,3)); \\\n",
    "                commit;\"\n",
    "        cur.execute(q)\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    cur.execute(\"commit;\")\n",
    "    db.close()\n",
    "\n",
    "\n",
    "# STORE THE CLEANED TWEETS WITH THE SENTIMENT ANALYSIS RESULTS IN A NEW TABLE IN DATABASE cl_tweets\n",
    "try:\n",
    "    db = mysql.connector.connect(host='localhost', database='twit_sent_an', user='root', password='')\n",
    "    if db.is_connected():\n",
    "        print('Connected to MySQL Database')\n",
    "        cur = db.cursor()  # create object cursor from cursor method\n",
    "\n",
    "        for row in data.index:\n",
    "            q = \"INSERT INTO cl_tweets (username, tweet, t_date, n_ret, loc, n_fol, n_twe, hashtags, sentiment) VALUES ('\" \\\n",
    "            + str(data['user'][row]) + \"', '\" + str(data['tweet'][row]) + \"', '\" + str(data['date'][row]) + \\\n",
    "            \"', '\" + str(data['n_ret'][row]) + \"', '\" + str(data['loc'][row]) + \"', '\" + str(data['n_fol'][row]) + \\\n",
    "            \"', '\" + str(data['n_twe'][row]) + \"', '\"  + str(data['hashtags'][row]) + \\\n",
    "            \"', '\" + str(data['polarity'][row]) + \"');\"\n",
    "\n",
    "            cur.execute(q)\n",
    "\n",
    "except Error as e:\n",
    "    print(e)\n",
    "\n",
    "finally:\n",
    "    cur.execute(\"commit;\")\n",
    "    db.close()\n",
    "    print('Database connection closed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04ba74",
   "metadata": {},
   "source": [
    "# PROXEIRO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
